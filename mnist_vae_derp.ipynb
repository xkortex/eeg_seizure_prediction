{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: qt. Using tk instead.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plotting import plotstuff\n",
    "from imp import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''This script demonstrates how to build a variational autoencoder with Keras.\n",
    "\n",
    "Reference: \"Auto-Encoding Variational Bayes\" https://arxiv.org/abs/1312.6114\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import objectives\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# global\n",
    "nb_epoch = 50\n",
    "\n",
    "class VariationalAutoencoder(object):\n",
    "    def __init__(self, original_dim=784, latent_dim=2, intermediate_dim=256, batch_size=100, epsilon_std=1.0):\n",
    "        #vae params\n",
    "        self.batch_size = batch_size\n",
    "        self.original_dim = original_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.intermediate_dim = intermediate_dim\n",
    "        self.epsilon_std = epsilon_std\n",
    "\n",
    "        x = Input(batch_shape=(batch_size, original_dim), name='x_input')\n",
    "        h = Dense(intermediate_dim, activation='relu', name='h_hidden_relu_1')(x)\n",
    "        self.z_mean = Dense(latent_dim, name='Z_Mean')(h)\n",
    "        self.z_log_var = Dense(latent_dim, name='Z_Log_Var')(h)\n",
    "\n",
    "        # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "        z = Lambda(self.sampling, output_shape=(latent_dim,))([self.z_mean, self.z_log_var])\n",
    "\n",
    "        # we instantiate these layers separately so as to reuse them later\n",
    "        decoder_h = Dense(intermediate_dim, activation='relu', name='Decoder_H_Relu')\n",
    "        decoder_mean = Dense(original_dim, activation='sigmoid', name='Decoder_Mean_sig')\n",
    "        h_decoded = decoder_h(z)\n",
    "        x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "\n",
    "        self.model = Model(x, x_decoded_mean)\n",
    "        self.model.compile(optimizer='rmsprop', loss=self.vae_loss)\n",
    "\n",
    "        # build a model to project inputs on the latent space\n",
    "        self.encoder = Model(x, self.z_mean)\n",
    "\n",
    "        # build a digit generator that can sample from the learned distribution\n",
    "        decoder_input = Input(shape=(latent_dim,))\n",
    "        _h_decoded = decoder_h(decoder_input)\n",
    "        _x_decoded_mean = decoder_mean(_h_decoded)\n",
    "        self.generator = Model(decoder_input, _x_decoded_mean)\n",
    "\n",
    "\n",
    "    def vae_loss(self, x, x_decoded_mean):\n",
    "        xent_loss = self.original_dim * objectives.binary_crossentropy(x, x_decoded_mean)\n",
    "        kl_loss = - 0.5 * K.sum(1 + self.z_log_var - K.square(self.z_mean) - K.exp(self.z_log_var), axis=-1)\n",
    "        return xent_loss + kl_loss\n",
    "\n",
    "\n",
    "    def sampling(self, z_args):\n",
    "        \"Unpacks the tuple input and conducts probabilistic sampling\"\n",
    "        z_mean, z_log_var = z_args\n",
    "        epsilon = K.random_normal(shape=(self.batch_size, self.latent_dim), mean=0.,\n",
    "                                  std=self.epsilon_std)\n",
    "        return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "    def fit(self, x, y, batch_size=None, nb_epoch=10, verbose=1, callbacks=[], validation_split=0.,\n",
    "            validation_data=None, shuffle=True, class_weight=None, sample_weight=None):\n",
    "        callbacks_history = self.model.fit(x, y, batch_size, nb_epoch, verbose, callbacks, validation_split,\n",
    "                                           validation_data, shuffle, class_weight, sample_weight)\n",
    "        return callbacks_history\n",
    "\n",
    "\n",
    "vaeclass = VariationalAutoencoder(latent_dim=3)\n",
    "vae = vaeclass.model\n",
    "encoder = vaeclass.encoder\n",
    "generator = vaeclass.generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ==== dataset handling - train the VAE on MNIST digits ===\n",
    "batch_size = 100\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras.utils.visualize_util\n",
    "keras.utils.visualize_util.plot(vae, 'vae.png', show_shapes=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 5s - loss: 179.8274 - val_loss: 160.8565\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 4s - loss: 156.8364 - val_loss: 154.0167\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 5s - loss: 152.8201 - val_loss: 151.1961\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 4s - loss: 150.2200 - val_loss: 149.0433\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s - loss: 148.3109 - val_loss: 147.6591\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 5s - loss: 146.8545 - val_loss: 146.1676\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 4s - loss: 145.6747 - val_loss: 145.2551\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 4s - loss: 144.7206 - val_loss: 144.8867\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 5s - loss: 143.9576 - val_loss: 143.8035\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 4s - loss: 143.2941 - val_loss: 143.3321\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 4s - loss: 142.7257 - val_loss: 143.0540\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 5s - loss: 142.2421 - val_loss: 142.4111\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 4s - loss: 141.8040 - val_loss: 141.9666\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 4s - loss: 141.4324 - val_loss: 141.6182\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 4s - loss: 141.1014 - val_loss: 141.5312\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 4s - loss: 140.7847 - val_loss: 141.0080\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 4s - loss: 140.5191 - val_loss: 141.2179\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 4s - loss: 140.2508 - val_loss: 141.2078\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 4s - loss: 140.0160 - val_loss: 140.7188\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 4s - loss: 139.7855 - val_loss: 140.3633\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 5s - loss: 139.5820 - val_loss: 140.0027\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 4s - loss: 139.4067 - val_loss: 140.2069\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 4s - loss: 139.2215 - val_loss: 140.1129\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 4s - loss: 139.0531 - val_loss: 139.7594\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 5s - loss: 138.8982 - val_loss: 139.8946\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 4s - loss: 138.7320 - val_loss: 139.7831\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 4s - loss: 138.5987 - val_loss: 139.4293\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 5s - loss: 138.4536 - val_loss: 139.5115\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 4s - loss: 138.3527 - val_loss: 139.3745\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 4s - loss: 138.2346 - val_loss: 139.4502\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 4s - loss: 138.0899 - val_loss: 138.9993\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 4s - loss: 137.9633 - val_loss: 139.1437\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 4s - loss: 137.8539 - val_loss: 138.8936\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 4s - loss: 137.7069 - val_loss: 138.8948\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 4s - loss: 137.6442 - val_loss: 138.9124\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 4s - loss: 137.4869 - val_loss: 138.7766\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 4s - loss: 137.4535 - val_loss: 138.7056\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 4s - loss: 137.3415 - val_loss: 138.8058\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 4s - loss: 137.2208 - val_loss: 138.5119\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 4s - loss: 137.1255 - val_loss: 138.3912\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 4s - loss: 137.0388 - val_loss: 138.5829\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 4s - loss: 136.9627 - val_loss: 138.5468\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 4s - loss: 136.9030 - val_loss: 138.5332\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 4s - loss: 136.8088 - val_loss: 138.6183\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 4s - loss: 136.7216 - val_loss: 138.3522\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 4s - loss: 136.6414 - val_loss: 138.2949\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 4s - loss: 136.5648 - val_loss: 137.9600\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 4s - loss: 136.5025 - val_loss: 137.9256\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 5s - loss: 136.4462 - val_loss: 138.3249\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 4s - loss: 136.3465 - val_loss: 138.6062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbdc8e39ad0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assert 0, 'pause'\n",
    "vae.fit(x_train, x_train,\n",
    "        shuffle=True,\n",
    "        nb_epoch=nb_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<plotting.plotstuff.Easy3dScatter at 0x7fbcf7b7fa90>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== plotting encoder output\n",
    "# display a 2D plot of the digit classes in the latent space\n",
    "reload(plotstuff)\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plotstuff.Easy3dScatter(plt, x_test_encoded, '', s=10, c=y_test )\n",
    "\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 2], c=y_test)\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ====== plotting decoder from latent space =======\n",
    "# display a 2D manifold of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "ss=4\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# we will sample n points within [-15, 15] standard deviations\n",
    "grid_x = np.linspace(-ss, ss, n)\n",
    "grid_y = np.linspace(-ss, ss, n)\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = generator.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test some digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_digit(z_sample, digit_size = 28, n=1):\n",
    "    z_sample = np.array(z_sample).reshape(1,2)\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    x_decoded = generator.predict(z_sample)\n",
    "    digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "    i, j = 0,0\n",
    "    figure[i * digit_size: (i + 1) * digit_size,\n",
    "           j * digit_size: (j + 1) * digit_size] = digit\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(figure)\n",
    "    plt.show()\n",
    "    \n",
    "draw_digit((4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert 0, 'halt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build a digit generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)\n",
    "\n",
    "# display a 2D manifold of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# we will sample n points within [-15, 15] standard deviations\n",
    "ss = 3\n",
    "grid_x = np.linspace(-ss, ss, n)\n",
    "grid_y = np.linspace(-ss, ss, n)\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = generator.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convo VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''This script demonstrates how to build a variational autoencoder\n",
    "with Keras and deconvolution layers.\n",
    "\n",
    "Reference: \"Auto-Encoding Variational Bayes\" https://arxiv.org/abs/1312.6114\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from keras.layers import Convolution2D, Deconvolution2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import objectives\n",
    "from keras.datasets import mnist\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0., std=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var) * epsilon\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    # NOTE: binary_crossentropy expects a batch_size by dim\n",
    "    # for x and x_decoded_mean, so we MUST flatten these!\n",
    "    x = K.flatten(x)\n",
    "    x_decoded_mean = K.flatten(x_decoded_mean)\n",
    "    xent_loss = img_rows * img_cols * objectives.binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols, img_chns = 28, 28, 1\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 64\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "\n",
    "batch_size = 100\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    original_img_size = (img_chns, img_rows, img_cols)\n",
    "else:\n",
    "    original_img_size = (img_rows, img_cols, img_chns)\n",
    "latent_dim = 2\n",
    "intermediate_dim = 128\n",
    "epsilon_std = 1.0\n",
    "nb_epoch = 5\n",
    "\n",
    "x = Input(batch_shape=(batch_size,) + original_img_size)\n",
    "conv_1 = Convolution2D(img_chns, 2, 2, border_mode='same', activation='relu')(x)\n",
    "conv_2 = Convolution2D(nb_filters, 2, 2,\n",
    "                       border_mode='same', activation='relu',\n",
    "                       subsample=(2, 2))(conv_1)\n",
    "conv_3 = Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                       border_mode='same', activation='relu',\n",
    "                       subsample=(1, 1))(conv_2)\n",
    "conv_4 = Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                       border_mode='same', activation='relu',\n",
    "                       subsample=(1, 1))(conv_3)\n",
    "flat = Flatten()(conv_4)\n",
    "hidden = Dense(intermediate_dim, activation='relu')(flat)\n",
    "\n",
    "z_mean = Dense(latent_dim)(hidden)\n",
    "z_log_var = Dense(latent_dim)(hidden)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_var])`\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_hid = Dense(intermediate_dim, activation='relu')\n",
    "decoder_upsample = Dense(nb_filters * 14 * 14, activation='relu')\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    output_shape = (batch_size, nb_filters, 14, 14)\n",
    "else:\n",
    "    output_shape = (batch_size, 14, 14, nb_filters)\n",
    "\n",
    "decoder_reshape = Reshape(output_shape[1:])\n",
    "decoder_deconv_1 = Deconvolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                                   output_shape,\n",
    "                                   border_mode='same',\n",
    "                                   subsample=(1, 1),\n",
    "                                   activation='relu')\n",
    "decoder_deconv_2 = Deconvolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                                   output_shape,\n",
    "                                   border_mode='same',\n",
    "                                   subsample=(1, 1),\n",
    "                                   activation='relu')\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    output_shape = (batch_size, nb_filters, 29, 29)\n",
    "else:\n",
    "    output_shape = (batch_size, 29, 29, nb_filters)\n",
    "decoder_deconv_3_upsamp = Deconvolution2D(nb_filters, 2, 2,\n",
    "                                          output_shape,\n",
    "                                          border_mode='valid',\n",
    "                                          subsample=(2, 2),\n",
    "                                          activation='relu')\n",
    "decoder_mean_squash = Convolution2D(img_chns, 2, 2,\n",
    "                                    border_mode='valid',\n",
    "                                    activation='sigmoid')\n",
    "\n",
    "hid_decoded = decoder_hid(z)\n",
    "up_decoded = decoder_upsample(hid_decoded)\n",
    "reshape_decoded = decoder_reshape(up_decoded)\n",
    "deconv_1_decoded = decoder_deconv_1(reshape_decoded)\n",
    "deconv_2_decoded = decoder_deconv_2(deconv_1_decoded)\n",
    "x_decoded_relu = decoder_deconv_3_upsamp(deconv_2_decoded)\n",
    "x_decoded_mean_squash = decoder_mean_squash(x_decoded_relu)\n",
    "\n",
    "\n",
    "vae = Model(x, x_decoded_mean_squash)\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss)\n",
    "vae.summary()\n",
    "\n",
    "# train the VAE on MNIST digits\n",
    "(x_train, _), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = x_train.reshape((x_train.shape[0],) + original_img_size)\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test = x_test.reshape((x_test.shape[0],) + original_img_size)\n",
    "\n",
    "print('x_train.shape:', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vae.fit(x_train, x_train,\n",
    "        shuffle=True,\n",
    "        nb_epoch=nb_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# display a 2D plot of the digit classes in the latent space\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# display a 2D manifold of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# we will sample n points within [-15, 15] standard deviations\n",
    "grid_x = np.linspace(-15, 15, n)\n",
    "grid_y = np.linspace(-15, 15, n)\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        z_sample = np.tile(z_sample, batch_size).reshape(batch_size, 2)\n",
    "        x_decoded = generator.predict(z_sample, batch_size=batch_size)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
