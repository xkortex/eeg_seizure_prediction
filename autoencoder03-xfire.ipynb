{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from boilerplate import *\n",
    "from __future__ import print_function, division\n",
    "import os, sys\n",
    "import functional_vectorizer\n",
    "from dio import dataio as dataio\n",
    "from scipy import fftpack, signal, special\n",
    "from imp import reload\n",
    "style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# LSTM and CNN for sequence classification in the IMDB dataset\n",
    "import numpy\n",
    "numpy.random.seed(7)\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, BatchNormalization, Dropout, GaussianDropout, GaussianNoise\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Convolution1D, Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling1D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras import regularizers\n",
    "from keras.utils import np_utils\n",
    "from sklearn import manifold\n",
    "# fix random seed for reproducibility\n",
    "import numpy as np, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/mike/ve/ml/')\n",
    "from eegkaggle.models import crossfire, neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (12,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'eegkaggle.dio.dataio' from 'eegkaggle/dio/dataio.pyc'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eegkaggle.dio.dataio as dataio\n",
    "reload(dataio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data = np.load('/run/media/mike/Elements/data/kaggle/melbourne/vectors/simple_fft_vectorizedata_train_1_X.npy')\n",
    "# data = np.load('/home/mike/ve/ml/vec_sampen_9598_376.npy')\n",
    "# Y = np.load('/run/media/mike/Elements/data/kaggle/melbourne/vectors/simple_fft_vectorizedata_train_1_Y.npy')\n",
    "data, Y = dataio.reload_with_labels('/home/mike/ve/ml/vec_sampen_9598_376')\n",
    "data_g, Y_g = dataio.reload_with_labels('/home/mike/ve/ml/vec_sampen_9607_384')\n",
    "files1 = pd.read_csv('/home/mike/ve/ml/vec_sampen_9598_376_name.csv')\n",
    "files2 = pd.read_csv('/home/mike/ve/ml/vec_sampen_9607_384_name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_cut:  220\n",
      "(5600, 16384) (5600, 1) (440, 16384) (440, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = dataio.subdiv_split_shuffle(data, Y, validation_split=.49, )\n",
    "x_guess = data_g\n",
    "x_train = x_train[:5600] # trimming for batch processing later\n",
    "y_train = y_train[:5600]\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(y_train).to_csv('y_train.csv')\n",
    "# pd.DataFrame(y_test).to_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# need to do this later\n",
    "# d = dataio.subdiv_and_shuffle(x_train, y_train, resample='down')\n",
    "# print(d[0].shape, d[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-e6a7f31924a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_g\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mY_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_g\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfiles_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfiles1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "data_a = np.concatenate([data, data_g], axis=0)\n",
    "Y_a = np.concatenate([Y, Y_g ], axis=0)\n",
    "files_a = pd.concat([files1, files2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7949, 16384) (7949, 1) (7949, 2) [-0.1835451]\n"
     ]
    }
   ],
   "source": [
    "print(data_a.shape, Y_a.shape, files_a.shape, np.mean(Y_a, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# files.to_csv('vec_enc_lf256_16_each_label_names.csv')\n",
    "# np.save('vec_enc_lf256_16_each_label', Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5600, 16384) (440, 16384) (1908, 1024, 16)\n",
      "(5600, 1024, 16) (440, 1024, 16) (1908, 1024, 16)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape, data_g.shape)\n",
    "data_r = x_train.reshape(x_train.shape[0], -1, 16)\n",
    "data_t = x_test.reshape(x_test.shape[0], -1, 16)\n",
    "data_g = x_guess.reshape(data_g.shape[0], -1, 16)\n",
    "\n",
    "# d0 = d0.reshape(d0.shape[0, -1, 16])\n",
    "# d1 = d1.reshape(d1.shape[0, -1, 16])\n",
    "# data_a = data_a.reshape(data_a.shape[0], -1, 16)\n",
    "\n",
    "print(data_r.shape, data_t.shape, data_g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16384,)\n"
     ]
    }
   ],
   "source": [
    "# plot(data[0])\n",
    "print(data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = np.std(data, axis=0)\n",
    "# plt.plot(data[100]/std)\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5600, 1024, 16) (440, 1024, 16) (1908, 1024, 16)\n",
      "(5600, 64, 16) (440, 64, 16) (1908, 64, 16)\n"
     ]
    }
   ],
   "source": [
    "# Smooth the std?\n",
    "# data_rs = signal.resample(data, 256, axis=1)\n",
    "print(data_r.shape, data_t.shape, data_g.shape)\n",
    "up, down = 4, 64\n",
    "data_r_rs = signal.resample_poly(data_r, up, down, axis=1)\n",
    "# data_rs = data_rs.reshape(data_rs.shape[0], 32, 32) # this is actually wrong\n",
    "data_t_rs = signal.resample_poly(data_t, up, down, axis=1)\n",
    "data_g_rs = signal.resample_poly(data_g, up, down, axis=1)\n",
    "\n",
    "# data_t_rs = data_t_rs.reshape(data_t_rs.shape[0], 32, 32)\n",
    "print(data_r_rs.shape, data_t_rs.shape, data_g_rs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 16)\n"
     ]
    }
   ],
   "source": [
    "std = np.std(data_r_rs,axis=0)\n",
    "# plt.plot(data_rs[100]/std)\n",
    "# plt.imshow(data_r_rs[100]/std)\n",
    "print(data_r_rs[100].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(np.concatenate([data_rs[100,:32], data_rs[100,32:]], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5600, 32, 32) (440, 32, 32) (1908, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "new_data = np.zeros((data_r_rs.shape[0], 32, 32))\n",
    "new_test = np.zeros((data_t_rs.shape[0], 32, 32))\n",
    "new_guess = np.zeros((data_g_rs.shape[0], 32, 32))\n",
    "\n",
    "for i in range(data_r_rs.shape[0]):\n",
    "    new_data[i] = np.concatenate([data_r_rs[i,:32], data_r_rs[i,32:]], axis=1)\n",
    "for i in range(data_t_rs.shape[0]):\n",
    "    new_test[i] = np.concatenate([data_t_rs[i,:32], data_t_rs[i,32:]], axis=1)\n",
    "for i in range(data_g_rs.shape[0]):\n",
    "    new_guess[i] = np.concatenate([data_g_rs[i,:32], data_g_rs[i,32:]], axis=1)\n",
    "data_r_rs = new_data\n",
    "data_t_rs = new_test\n",
    "data_g_rs = new_guess\n",
    "print(data_r_rs.shape, data_t_rs.shape, data_g_rs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(data_r_rs[105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_cls = np_utils.to_categorical(np.asarray(y_train, dtype=int), 2)\n",
    "y_test_cls = np_utils.to_categorical(np.asarray(y_test, dtype=int), 2)\n",
    "\n",
    "# print(y_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = np.mean(data_r_rs, axis=0)\n",
    "std = np.std(data_r_rs, axis=0)\n",
    "# gmean = np.mean(data)\n",
    "# gstd = np.std(data)\n",
    "# mean.shape, gstd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min -2.10708184604 max: 5.27072193084\n",
      "(5600, 32, 32) (440, 32, 32) (5600, 1) (440, 1)\n"
     ]
    }
   ],
   "source": [
    "# zdata = (data_rs - mean) / (std*4)\n",
    "zdata = (data_r_rs) / (std*4)\n",
    "zdata_t = (data_t_rs) / (std*4)\n",
    "zdata_g = (data_g_rs) / (std*4)\n",
    "\n",
    "print('min {} max: {}'.format(np.amin(zdata), np.amax(zdata)))\n",
    "zdata = np.nan_to_num(zdata)\n",
    "zdata_t = np.nan_to_num(zdata_t)\n",
    "zdata_g = np.nan_to_num(zdata_g)\n",
    "\n",
    "print(zdata.shape, zdata_t.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n"
     ]
    }
   ],
   "source": [
    "# plt.plot(zdata[100,:])\n",
    "print(zdata[100].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plt.plot(zdata_t[1900])\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(zdata[101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = dataio.get_matlab_eeg_data_ary('/home/mike/data/train/1_1001_0.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5600, 32, 32) (440, 32, 32) (6041, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ds = signal.resample(zdata[0:], 256, axis=1)\n",
    "ds = zdata\n",
    "ds = np.tanh(ds)\n",
    "x_test = np.tanh(zdata_t)\n",
    "x_guess = np.tanh(zdata_g)\n",
    "\n",
    "# ds = np.log(ds)\n",
    "# ds = special.erf(ds)\n",
    "print(ds.shape,  x_test.shape, Y.shape,)\n",
    "# plt.plot(ds[4000])\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43299654551 0.421841146506\n",
      "0.206965885473 0.206536117584\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(ds), np.mean(x_test))\n",
    "print(np.std(ds), np.std(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ds2 = ds.reshape(ds.shape[0], -1)\n",
    "# ds2 = ds.reshape(ds.shape[0]*16, -1)\n",
    "# Serialize the electrodes so that there is 1 electrode per sample\n",
    "# ds2 = []\n",
    "# for i in range(16):\n",
    "#     ds2.append( ds[:,:,i])\n",
    "# ds2 = np.concatenate(ds2, axis=0)\n",
    "# ds2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 1) (5600, 32, 32, 1) (440, 32, 32, 1) (1908, 32, 32, 1) (5600, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train = ds.reshape((ds.shape[0], ds.shape[1], ds.shape[2], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], x_test.shape[2], 1))\n",
    "x_guess = x_guess.reshape((x_guess.shape[0], x_guess.shape[1], x_guess.shape[2], 1))\n",
    "\n",
    "input_shape = (ds.shape[1], ds.shape[2], 1)\n",
    "\n",
    "batch_size=100\n",
    "print(input_shape, x_train.shape, x_test.shape, x_guess.shape, y_train_cls.shape)\n",
    "# vaeclass = crossfire.CrossfireEEG(input_shape=input_shape, latent_dim=16, batch_size=batch_size, n_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inline building of ConvAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleCrossfire(object):\n",
    "    \"\"\"\n",
    "    Covolutional VAE with a \"crossfire\" component - a classifier is bolted onto the end of the encoder and loss function\n",
    "    can be parameterized to function from classifier loss instead of autoencoder loss. Ideally, the model starts in\n",
    "    pure autoencoder mode to learn features, then as loss flattens out the network starts weighing classifier loss\n",
    "    more heavily.\n",
    "    Refs: \n",
    "    https://stackoverflow.com/questions/39181976/keras-convolutional-autoencoder-layer-shapes\n",
    "    Note to self: things to try:\n",
    "    * Add burst /batch / epoch noise to input\n",
    "    * Modularize out the activation from dropout ordering\"\"\"\n",
    "\n",
    "    def __init__(self, input_shape=(28, 28, 1), latent_dim=2, intermediate_dim=256, batch_size=100, epsilon_std=1.0,\n",
    "                 dropout_p=0.1, n_stax=0, n_classes=10):\n",
    "        # input image dimensions\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.original_dim = np.prod(input_shape)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.intermediate_dim = intermediate_dim\n",
    "        self.epsilon_std = epsilon_std\n",
    "        self.epsilon_ce = 1.0e-9\n",
    "\n",
    "        # number of convolutional filters to use\n",
    "        nb_filters = 64\n",
    "        # convolution kernel size\n",
    "        nb_conv = 3\n",
    "\n",
    "        input_img = Input(shape=(1, input_shape[0], input_shape[1]))\n",
    "\n",
    "        # Same as the code above, but with some params changed\n",
    "        # Now let's define the model.\n",
    "\n",
    "        # (no.of, colour, channels, height, width) = (3, 30, 30)\n",
    "        # Set input dimensions:\n",
    "        imchn = 3  # channels\n",
    "        imwid = 30 # width\n",
    "        imhei = 30 # height\n",
    "        input_img = Input(shape=(imchn, imhei, imwid))\n",
    "        nb_filters1 = 128\n",
    "        nb_filters2 = 64\n",
    "        nb_filters3 = 64\n",
    "\n",
    "        # Encoder: define a chain of Conv2D and MaxPooling2D layers\n",
    "        x = Convolution2D(128, nb_conv, nb_conv, activation='relu', border_mode='same')(input_img)\n",
    "        x = MaxPooling2D((2, 2), border_mode='same')(x)\n",
    "        x = Convolution2D(64, nb_conv, nb_conv, activation='relu', border_mode='same')(x)\n",
    "        x = MaxPooling2D((2, 2), border_mode='same')(x)\n",
    "        x = Convolution2D(64, nb_conv, nb_conv, activation='relu', border_mode='same')(x)\n",
    "        encoded = MaxPooling2D((2, 2), border_mode='same')(x)\n",
    "\n",
    "        # at this point, the representation is (8, 4, 4) i.e. 128-dimensional\n",
    "\n",
    "        # Decoder: a stack of Conv2D and UpSampling2D layers\n",
    "        x = Convolution2D(64, nb_conv, nb_conv, activation='relu', border_mode='same')(encoded)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Convolution2D(64, nb_conv, nb_conv, activation='relu', border_mode='same')(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Convolution2D(128, nb_conv, nb_conv, activation='relu', border_mode='same')(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        decoded = Convolution2D(1, 3, 3, activation='sigmoid', border_mode='same')(x)\n",
    "        # Generate models\n",
    "        # Primary model - VAE\n",
    "        ## ==== Crossfire classifier =========\n",
    "        #         c = Lambda(self.crosser, output_shape=(latent_dim,))(self.z_mean, self.z_log_var)\n",
    "#         classer = Dense(n_classes, init='normal', activation='softmax', name='classer')(encoded)\n",
    "#         self.ae = Model(input_img, decoded)\n",
    "#         self.ae.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "        self.ae = Model(input_img, decoded)\n",
    "        self.ae.compile(optimizer='adadelta', loss='mse')\n",
    "        # Crossfilre network\n",
    "        if False:\n",
    "            self.classifier = Model(x, classer)\n",
    "            # Ok, now comes the tricky part. See these references:\n",
    "            # https://keras.io/getting-started/functional-api-guide/#multi-input-and-multi-output-models\n",
    "            self.crossmodel = Model(input=x, output=[decoded, classer])\n",
    "            self.crossmodel.compile(optimizer='rmsprop',\n",
    "                                    loss={'main_output': self.vae_loss,\n",
    "                                          'classer': 'categorical_crossentropy'},\n",
    "                                    loss_weights={'main_output': 1.0,\n",
    "                                                  'classer': 1.0})\n",
    "            self.classifier.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            # self.classifier.compile(loss=self.custom_crossent, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        # build a model to project inputs on the latent space\n",
    "#         self.encoder = Model(x, encoded)\n",
    "        # reconstruct digits from latent space\n",
    "        # self.generator = Model(decoder_input, _x_decoded_mean_squash)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# not in use at the moment\n",
    "#vaeclass = SimpleCrossfire(input_shape=input_shape, latent_dim=16, batch_size=batch_size, n_classes=2)\n",
    "# vaeclass.ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cnnclass = neural.Simple_Convo_Classer(input_shape[0:2], nb_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assert 0\n",
    "from keras import objectives\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras import models\n",
    "import keras.layers.core as core\n",
    "import keras.layers.convolutional as conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5600, 32, 32)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "gaussiannoise_2 (GaussianNoise)  (None, 32, 32, 1)     0           gaussiannoise_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 32, 32, 1)     0           gaussiannoise_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_21 (Convolution2D) (None, 32, 32, 32)    320         dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNormal(None, 32, 32, 32)    64          convolution2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 32, 32, 32)    0           batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_22 (Convolution2D) (None, 32, 32, 32)    9248        dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 16, 16, 32)    0           convolution2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_23 (Convolution2D) (None, 16, 16, 64)    18496       maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_24 (Convolution2D) (None, 16, 16, 64)    36928       convolution2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 8, 8, 64)      0           convolution2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 4096)          0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 4096)          0           flatten_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 128)           524416      dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 2)             258         dense_11[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 589730\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "img_rows, img_cols = 32, 32\n",
    "nb_classes = 2\n",
    "\n",
    "nb_filters_1 = 32  # 32 # 64\n",
    "nb_filters_2 = 64  # 64 # 128\n",
    "nb_filters_3 = 128  # 128 # 256\n",
    "nb_conv = 3\n",
    "\n",
    "trainX = ds\n",
    "print(trainX.shape)\n",
    "sigma= 0.1\n",
    "drop_p=0.2\n",
    "\n",
    "cnn = models.Sequential()\n",
    "cnn.add(GaussianNoise(sigma, input_shape=(img_rows, img_cols, 1)))\n",
    "cnn.add(Dropout(drop_p))\n",
    "cnn.add(conv.Convolution2D(nb_filters_1, nb_conv, nb_conv, activation=\"relu\",border_mode='same'))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Dropout(drop_p))\n",
    "cnn.add(conv.Convolution2D(nb_filters_1, nb_conv, nb_conv, activation=\"relu\", border_mode='same'))\n",
    "cnn.add(conv.MaxPooling2D(strides=(2, 2)))\n",
    "\n",
    "cnn.add(conv.Convolution2D(nb_filters_2, nb_conv, nb_conv, activation=\"relu\", border_mode='same'))\n",
    "cnn.add(conv.Convolution2D(nb_filters_2, nb_conv, nb_conv, activation=\"relu\", border_mode='same'))\n",
    "cnn.add(conv.MaxPooling2D(strides=(2, 2)))\n",
    "\n",
    "# cnn.add(conv.Convolution2D(nb_filters_3, nb_conv, nb_conv, activation=\"relu\", border_mode='same'))\n",
    "# cnn.add(conv.Convolution2D(nb_filters_3, nb_conv, nb_conv, activation=\"relu\", border_mode='same'))\n",
    "# cnn.add(conv.Convolution2D(nb_filters_3, nb_conv, nb_conv, activation=\"relu\", border_mode='same'))\n",
    "# cnn.add(conv.Convolution2D(nb_filters_3, nb_conv, nb_conv, activation=\"relu\", border_mode='same'))\n",
    "# cnn.add(conv.MaxPooling2D(strides=(2,2)))\n",
    "\n",
    "cnn.add(core.Flatten())\n",
    "cnn.add(core.Dropout(0.2))\n",
    "cnn.add(core.Dense(128, activation=\"relu\"))  # 4096\n",
    "cnn.add(core.Dense(nb_classes, activation=\"softmax\"))\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5593, 32, 32, 1) (5593, 2) (448, 32, 32, 1) (448, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train_cls.shape, x_test.shape, y_test_cls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5368.,   225.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_train_cls, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(dataio)\n",
    "x_sub, y_sub = dataio.shuffle_split_with_label(x_train, y_train, seed=i)\n",
    "y_sub_cls = np_utils.to_categorical(np.asarray(y_sub, dtype=int), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-af071dcb5f42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnb_mega\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_mega\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mega-epoch {} of {}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_mega\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 0\n",
    "nb_mega = 10\n",
    "for i in range(nb_mega):\n",
    "    print('Mega-epoch {} of {}', i, nb_mega)\n",
    "    seed = i\n",
    "#     np.random.seed(seed)\n",
    "#     np.random.shuffle(ds)\n",
    "#     np.random.seed(seed)\n",
    "#     np.random.shuffle(Y_cls)\n",
    "    x_sub, y_sub = dataio.shuffle_split_with_label(x_train, y_train, seed=i)\n",
    "    y_sub_cls = np_utils.to_categorical(np.asarray(y_sub, dtype=int), 2)\n",
    "    cnn.fit(x_sub, y_sub_cls, batch_size=batch_size, nb_epoch=3, validation_data=(x_test, y_test_cls), shuffle=True) #, class_weight={0:y_wts[0], 1:y_wts[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5600, 32, 32, 1), (440, 32, 32, 1), (5600, 1))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5600, 28, 28, 1), (440, 28, 28, 1))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2 = x_train[:,:28, :28]\n",
    "x_test2 = x_test[:,:28, :28]\n",
    "x_train2.shape, x_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5600, 1), (440, 1))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(crossfire)\n",
    "batch_size=100\n",
    "cf = crossfire.Crossfire2((28,28,1), latent_dim=16, batch_size=batch_size, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5600/5600 [==============================] - 9s - loss: 1080.2588     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd92085aed0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf.fit_ae(x_train2, batch_size=batch_size, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "5600/5600 [==============================] - 3s - loss: 0.1645 - acc: 0.9593 - val_loss: 0.6854 - val_acc: 0.5500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd920345b90>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mega-epoch {} of {} 0 10\n",
      "Train on 5600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "5600/5600 [==============================] - 3s - loss: 0.1620 - acc: 0.9593 - val_loss: 0.6826 - val_acc: 0.5500\n",
      "Mega-epoch {} of {} 1 10\n",
      "Train on 5600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "5600/5600 [==============================] - 3s - loss: 0.1591 - acc: 0.9593 - val_loss: 0.6816 - val_acc: 0.5500\n",
      "Mega-epoch {} of {} 2 10\n",
      "Train on 5600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "5600/5600 [==============================] - 3s - loss: 0.1571 - acc: 0.9593 - val_loss: 0.6798 - val_acc: 0.5500\n",
      "Mega-epoch {} of {} 3 10\n",
      "Train on 5600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "5600/5600 [==============================] - 3s - loss: 0.1539 - acc: 0.9593 - val_loss: 0.6712 - val_acc: 0.5500\n",
      "Mega-epoch {} of {} 4 10\n",
      "Train on 5600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "5600/5600 [==============================] - 3s - loss: 0.1493 - acc: 0.9593 - val_loss: 0.6646 - val_acc: 0.5500\n",
      "Mega-epoch {} of {} 5 10\n",
      "Train on 5600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "5600/5600 [==============================] - 3s - loss: 0.1467 - acc: 0.9595 - val_loss: 0.6851 - val_acc: 0.5500\n",
      "Mega-epoch {} of {} 6 10\n",
      "Train on 5600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "5600/5600 [==============================] - 3s - loss: 0.1457 - acc: 0.9591 - val_loss: 0.6755 - val_acc: 0.5500\n",
      "Mega-epoch {} of {} 7 10\n",
      "Train on 5600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "5600/5600 [==============================] - 3s - loss: 0.1397 - acc: 0.9596 - val_loss: 0.7039 - val_acc: 0.5500\n",
      "Mega-epoch {} of {} 8 10\n",
      "Train on 5600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "5600/5600 [==============================] - 3s - loss: 0.1341 - acc: 0.9591 - val_loss: 0.7642 - val_acc: 0.5500\n",
      "Mega-epoch {} of {} 9 10\n",
      "Train on 5600 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "5600/5600 [==============================] - 3s - loss: 0.1318 - acc: 0.9596 - val_loss: 0.7636 - val_acc: 0.5575\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nb_mega = 10\n",
    "for i in range(nb_mega):\n",
    "    print('Mega-epoch {} of {}', i, nb_mega)\n",
    "    seed = i\n",
    "    x_sub, y_sub = dataio.shuffle_split_with_label(x_train2, y_train, seed=i)\n",
    "    y_sub_cls = np_utils.to_categorical(np.asarray(y_sub, dtype=int), 2)\n",
    "    cf.classifier.fit(x_train2, y_train_cls, batch_size=batch_size, nb_epoch=1, validation_data=(x_test2[:400], y_test_cls[:400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5593, 2)\n"
     ]
    }
   ],
   "source": [
    "pred = cnn.predict(x_train, batch_size=batch_size)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction distribution:  [ 0.50044699  0.49955301]\n"
     ]
    }
   ],
   "source": [
    "pred_c = pred > 0.5\n",
    "print('Prediction distribution: ', np.mean(pred_c, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy:  [ 0.53423923  0.53423923]\n"
     ]
    }
   ],
   "source": [
    "print('Training Set Accuracy: ', np.mean(pred_c == y_train_cls, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448, 2)\n",
      "(448, 2) (448, 2)\n",
      "Prediction distribution:  [ 0.37053571  0.62946429]\n",
      "Test Set Accuracy:  [ 0.69642857  0.69642857]\n"
     ]
    }
   ],
   "source": [
    "pred_test = cnn.predict(x_test, batch_size=batch_size)\n",
    "print(pred_test.shape)\n",
    "pred_c = pred_test > 0.5\n",
    "print(pred_c.shape, y_test_cls.shape)\n",
    "print('Prediction distribution: ', np.mean(pred_c, axis=0))\n",
    "print('Test Set Accuracy: ', np.mean(pred_c == y_test_cls, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "guess = cnn.predict(x_guess, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.48689727,  0.51310273])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess_c = guess > 0.5\n",
    "np.mean(guess_c, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.51380837,  0.48619169], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(guess, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f66ff05b110>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+0AAAH/CAYAAAAixjyqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRAbFTTsRERERERGRQf0PmS+mjhyEKQcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f66fb827e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(pred[:,0]).hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series(guess[:,0]).hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files2['Class'] = pd.Series(guess_c[:,0], dtype=int)\n",
    "files2['File'] = pd.Series([os.path.basename(nm) for nm in files2['path']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files2.to_csv('./eegkaggle/guesses/new_cnn_11_26_{}.csv'.format('a')) # fix this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder2.predict(x_train[:3000])\n",
    "decoded_imgs = decoder2.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    plot(decoded_imgs[np.random.randint(0, decoded_imgs.shape[0])])\n",
    "    \n",
    "plot(np.mean(decoded_imgs, axis=0), 'w--', lw=2)\n",
    "plot(np.mean(decoded_imgs, axis=0), 'r', lw=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1,20*17,17): \n",
    "    plt.plot(decoded_imgs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st = 2001\n",
    "n = 10\n",
    "nx = range(st,st+n*17,17)\n",
    "print(nx)\n",
    "c = ['r', 'g', 'b', 'm', 'c', 'y']\n",
    "for i in range(3):\n",
    "    j = nx[i]\n",
    "    plt.plot(decoded_imgs[j], c[i])\n",
    "    plt.plot(ds2[j], c[i]+'--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne1 = manifold.TSNE(2, 30, n_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txdata1 = tsne1.fit_transform(ds2[::15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne3 = manifold.TSNE(2, 30, n_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txdata3 = tsne3.fit_transform(ds2[::11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txdata1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "6041. / ( ds2.shape[0] / 16) * (ds2.shape[0] / 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nZeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txdata2 = np.array(txdata1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.scatter(txdata1[:,0], txdata1[:,1])\n",
    "nTrain = 6443\n",
    "nZeros = 5964\n",
    "cut = nZeros\n",
    "nOnes = nTrain-nZeros\n",
    "\n",
    "plt.scatter(txdata2[:cut,0], txdata2[:cut,1], c='w', s=5, marker='.',   edgecolors='none')\n",
    "plt.scatter(txdata2[cut:nTrain,0], txdata2[cut:nTrain,1], c='orange', s=500, marker='.', edgecolors='none', alpha=0.05)\n",
    "plt.scatter(txdata2[cut:nTrain,0], txdata2[cut:nTrain,1], c='r', s=10, marker='.', edgecolors='none')\n",
    "plt.scatter(txdata2[nTrain:,0], txdata2[nTrain:,1], c='b', s=10, marker='.', edgecolors='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "6041. / ( ds2.shape[0] / 16) * (ds2.shape[0] / 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nTrain = int(6041 * txdata3.shape[0] / (ds2.shape[0] / 16) )\n",
    "nZeros = int( nTrain * (5592/6041))\n",
    "cut = nZeros\n",
    "plt.scatter(txdata3[:cut,0], txdata3[:cut,1], c='w', s=5, marker='.',   edgecolors='none')\n",
    "plt.scatter(txdata3[cut:nTrain,0], txdata3[cut:nTrain,1], c='orange', s=500, marker='.', edgecolors='none', alpha=0.05)\n",
    "plt.scatter(txdata3[cut:nTrain,0], txdata3[cut:nTrain,1], c='r', s=10, marker='.', edgecolors='none')\n",
    "plt.scatter(txdata3[nTrain:,0], txdata3[nTrain:,1], c='b', s=10, marker='.', edgecolors='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ae2.save('ae_lf256_16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoder2.save('enc_lf256_16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoded_imgs.shape\n",
    "np.save('vec_enc_lf256_16_each', encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/mike/ve/ml/')\n",
    "from eegkaggle.dio import dataio\n",
    "reload(dataio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(dataio)\n",
    "print(zdata.shape, Y.shape)\n",
    "d0, d1, dt = dataio.separate_sets(zdata, Y)\n",
    "print(d0.shape, d1.shape)\n",
    "x,y = dataio.subdiv_and_shuffle(zdata, Y, resample='up', merge=False, shuffle=False) # let keras shuffle\n",
    "# x = zdata\n",
    "# y = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Yv = np.asarray(y == 1).ravel()\n",
    "print(Yv)\n",
    "Yv = np.stack([Yv, ~Yv], axis=1)\n",
    "print(Yv.shape)\n",
    "Yv = np.array(Yv, dtype=int)\n",
    "print(Yv.shape)\n",
    "np.mean(Yv[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(x.shape, Yv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = x\n",
    "# X_train = x.reshape(-1, 256,1)\n",
    "# X_train /= np.amax(X_train)\n",
    "y_train = Yv # .reshape(-1, 2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "ones_rate = np.mean(Yv[:,0])\n",
    "class_weight= {0:1./(1-ones_rate), 1:1./ones_rate}\n",
    "print(class_weight)\n",
    "model.fit(X_train, y_train, nb_epoch=3, batch_size=64, shuffle=True, class_weight=class_weight, validation_split=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pr = model.predict_classes(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(pr == y_train[:,1]) # MOMENT OF TRUUUUUTH!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
